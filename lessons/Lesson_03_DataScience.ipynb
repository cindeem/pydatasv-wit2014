{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Data Science\n",
      "\n",
      "##what is it\n",
      "\n",
      "##what is it trying to do\n",
      "\n",
      "##what is it used for\n",
      "\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Examples\n",
      "\n",
      "We will hear from \n",
      "\n",
      " * Miaoqing Fang from Facebook\n",
      " * Katheryn King from Eventbrite\n",
      " * Matar Hellar from UC Berkeley"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# More Examples\n",
      "\n",
      "Here are some examples of the type of work the women in this workshop are involved in...."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import Image"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Katy Huff\n",
      "\n",
      "* Before I run a nuclear reactor safety simulation, I use physics-based algorithms to aggregate, smooth, and restructure a fine-resolution, many-dimensional nuclear \"cross section\" (reaction probability) database into a lower-resolution, lower-dimensional library.\n",
      "\n",
      "###Miaoqing Fang (Facebook)\n",
      "\n",
      "* Together with the engineering team, we built a machine learning pipeline which estimates the likelihood of a facebook being authentic or fake\n",
      "\n",
      "###Katelyn Begany (UC Berkeley)\n",
      "\n",
      "* Machine learning helps me characterize \"networks\" of brain regions that work together during brain recordings.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(url='https://drive.google.com/uc?export=view&id=0B_YQRNNuzFaTcEpxUnBncWRjNmc')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"https://drive.google.com/uc?export=view&id=0B_YQRNNuzFaTcEpxUnBncWRjNmc\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "<IPython.core.display.Image at 0x104999290>"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I also use data science to understand how different areas of the brain are connected. This is an example of the wiring in a humab brain\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(url='https://drive.google.com/uc?export=view&id=0ByAA0OlPoQx6YTJzYzZGdlN4NFk')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"https://drive.google.com/uc?export=view&id=0ByAA0OlPoQx6YTJzYzZGdlN4NFk\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "<IPython.core.display.Image at 0x104999410>"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "\n",
      "###Lynn Root (Spotify)\n",
      "\n",
      " * Spotify uses data science to better recommend new music to users.  We have a \"Discover\" app within our client (mobile, web, and desktop) that suggests music based on what you listen to.  We also have a \"Radio\" app that will play music based on what you seed it (either an artist, a song, or an entire playlist) as well as what you have \"upvoted\" and \"downvoted\".  The Radio algorithm is based on general user behavior, as in - \"User X likes Band Y and Band W.  User Z is listening to Band Y right now, let's play something from Band W for User Z next\".  \n",
      " \n",
      " \n",
      " * We just acquired Echo Nest, which is very similar in trying to understand music trends.  But instead of user behavior driven music suggestions, it's more about music characteristics.  For instance, Band Y sounds very similar to Band Q because of the heavy bass lines, the influence from Band A, the beats-per-second, etc.  We will start incorporating more music \"genealogy\" driven suggestions rather than user behavior driven suggestion into Spotify.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "\n",
      "###Matar Haller (UC Berkeley)\n",
      "In our lab at UC Berkeley, we study how the human brain processes and represents \n",
      "complex information. We record brain signals from electrodes that are surgically placed \n",
      "under the skull, on the brain\u2019s surface. This technique is called electrocorticography \n",
      "(ECoG), and is used in patients who are undergoing brain surgery for clinical reasons. \n",
      "Because we record directly from the brain\u2019s surface, we can see when and where the \n",
      "brain is active. I use data science methods to look for patterns in brain activity that can \n",
      "be linked to specific aspects of perceiving, thinking, and doing. I find patterns in the brain activity where electrodes respond in the same way each time the person performs a task (principal component analysis). This lets me group electrodes according to how similar \n",
      "their responses are (clustering)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(url='https://drive.google.com/uc?export=view&id=0ByAA0OlPoQx6Z1FUS1EzZjNUOVU')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"https://drive.google.com/uc?export=view&id=0ByAA0OlPoQx6Z1FUS1EzZjNUOVU\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "<IPython.core.display.Image at 0x104999f50>"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(Image above) MRI image of the brain of a single subject with electrode locations. Each color is a cluster, so electrodes with the same color have similar activity patterns across time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(url='https://drive.google.com/uc?export=view&id=0ByAA0OlPoQx6ZFZHbU9adHl4MFk')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"https://drive.google.com/uc?export=view&id=0ByAA0OlPoQx6ZFZHbU9adHl4MFk\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "<IPython.core.display.Image at 0x104999590>"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "(Image above) Intraoperative picture of electrode grid placement in ECoG. Examples of 1cm and 4mm spacing between electrodes (top and bottom images, respectively)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Nataliya Nadtoka \n",
      "\n",
      "I have used some data mining methods in my PhD work in 3D animation to produce some\n",
      "automatic animations. In the movie below, I morph between expressions of one person in 3D and then morph between different identities. It's done using some statistical model. \n",
      "\n",
      "[Click link to see movie (opens in new window)](https://drive.google.com/file/d/0B_YQRNNuzFaTaHdTZ0NWX1ZvXzA0Xzc2N21zaUtVcU03dl9B/edit?usp=sharing)\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Rochelle Terman (UC Berkeley)\n",
      "\n",
      "* I'm writing my dissertation on human rights media. I used Python along with R to analyze 30 years of human rights news coverage. \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Image(url='https://drive.google.com/uc?export=view&id=0ByAA0OlPoQx6d043Mk5ZMlJGa3c')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<img src=\"https://drive.google.com/uc?export=view&id=0ByAA0OlPoQx6d043Mk5ZMlJGa3c\"/>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "<IPython.core.display.Image at 0x104999ad0>"
       ]
      }
     ],
     "prompt_number": 8
    }
   ],
   "metadata": {}
  }
 ]
}